---
title: "Chapter 1 - Linear Models"
output: 
   html_document:
    toc: yes
    toc_depth: 4
    css: ../../style.css
params:
  date: !r Sys.Date()    
---

```{r,setup, include=FALSE, eval=TRUE}
options(knitr.table.format = "html", width = 140)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, fig.width = 12, fig.height = 8)
```

<div>Author: Rick Dean</div>
<div>Article date: `r params$date`</div>

<div class="abstract">
  <p class="abstract">Abstract</p>
The following are notes, graphics, and R scripts from the text [Generalized Additive Models, An Introduction with R, Second Edition](https://www.routledge.com/Generalized-Add-itive-Models-An-Introduction-with-R-Second-Edition/Wood/p/book/9781498728331) by Simon N. Wood. References to this text are made with `[Wood]`.
</div>  

```{r, warning=FALSE, message=FALSE}
library(knitr)
library(kableExtra)
library(data.table)
library(gamair)
library(RplotterPkg)
library(RregressPkg)
library(RmatrixPkg)
```

## 1.3 The theory of linear models
### 1.3.1 Least squares estimation of $\beta$
We will be using the `gamair::sperm.comp1` data set and *RmatrixPkg::qr_householder()* for performing the QR decomposition. The data set is described in `[Wood, section 1.5.1 page 23]`. 

1. Load the data and define the predictor($\textbf{X}$) and response($\textbf{Y}$) matrices:
```{r}
data("sperm.comp1", package = "gamair")
sperm1_dt <- data.table::setDT(sperm.comp1)
sperm1_dt <- sperm1_dt[, .(count = count, time_ipc = time.ipc, prop_partner = prop.partner)]

n = nrow(sperm1_dt)


X_dt <- data.table(Intercept = rep(1, n))
X_dt[, `:=` (time_pc = sperm1_dt$time_ipc, prop_partner = sperm1_dt$prop_partner)]
p = ncol(X_dt) # number of predictors including the intercept

X <- as.matrix(X_dt)                  # n x p
y <- as.matrix(sperm1_dt[, .(count)]) # n x 1
```

2. Perform $\textbf{QR}$ decomposition of $\textbf{X}$ into its components $\textbf{Q}_{f}$ and $\textbf{R}$ `[Wood Equation 1.5 page 12]`
```{r}
X_qr <- RmatrixPkg::qr_householder(X)

Q <- X_qr$Q              # n x n
R <- X_qr$R[1:p, 1:p]    # p x p
```

3. Compute $t(\textbf{Q})\textbf{y}$ and assign vectors $\textbf{f}$ and $\textbf{r}$:
```{r}
Qy <- t(Q) %*% y                  # n x 1

f <- as.matrix(Qy[1:p,])          # p x 1
r <- as.matrix(Qy[(p + 1):n,])    # n - p x 1
```

4. Estimate the  $\beta$'s `[Wood Equation 1.6 page 12]`:
```{r}
R_inv <- solve(R)               # p x p
Beta_hat <- (R_inv %*% f)       # p x 1
```
<div class="takeaway">Take Away: Compare with $\beta_{j}$ at `[Wood, page 27]`</div><br>


5. Compute residual sum of squares from `[Wood, page 13]`:
```{r}
ssr <- drop(t(r) %*% r)
```

6. Compute residual standard error from `[Wood, page 28-29]`
```{r}
rse <- sqrt(ssr/(n - p))
```

### 1.3.2 The distribution of $\hat{\beta}$
### 1.3.3 $(\hat{\beta_{i}} - \beta_{i})/\hat{\sigma}_{\hat{\beta_{i}}} \sim t_{n-p}$

1. Estimate $\sigma^2$ (Equation 1.8 page 13):
```{r}
sigma_sq <- (t(r) %*% r)[1,1]/(n - p)
```

2. Compute covariance matrix of $\hat{\beta}$ (Equation 1.7 page 13):
```{r}
var_cov_beta <- R_inv %*% t(R_inv) * sigma_sq # p x p
```

3. Compute the standard error of $\hat{\beta}$ (page 14)
```{r}
var_beta <- diag(var_cov_beta)
se_beta <- sqrt(var_beta)
```
The $\hat{\beta}_{se}$ = `r se_beta`

### 1.3.4 $F$-ratio results

Testing if $\beta_{time_ipc}$ and $\beta_{prop_partner}$  = 0 (i.e. **$\beta_{1}$** = 0)

$H_{0}:\beta_{1} = 0$ versus  $H_{1}: \beta_{1} \ne 0$

1. Partition **X** into **X_0** and **X_1**:
```{r}
p = 3
q = 2

X_0 <- X[,1]
X_1 <- X[,2:3]
```

2. Partition **f** and compute the increase in residual sum of squares that results from dropping **X_1**:

```{r}
f_0 <- f[1]
f_1 <- f[2:3]

sse_minus_beta_1 <- (t(f_1) %*% f_1)[1,1]
```

3. Compute $F$ which follows an $F$ distribution with *q* (2) and *n - p* (12) degrees of freedom:
```{r}
F_val <- (sse_minus_beta_1/q)/sigma_sq
```

4. Compute the $F$ critical value with 2 and 12 df at 1% level
```{r}
F_cv <- qf(1 - 0.01, 2,12)
```
<div class="takeaway">Take Away: The $F$ is less than the critical value, so we do not reject the hypothesis that *time_ipc* and *prop_partner* are zero. We need more predictors than just the intercept alone in our model. </div><br>

## 1.5 Practical linear modeling

### 1.5.1 Model fitting and model checking
#### 1.5.1.1 Loading the data
```{r}
data("sperm.comp1", package = "gamair")
sperm1_dt <- data.table::setDT(sperm.comp1)
sperm1_dt <- sperm1_dt[, .(subject = subject, count = count, time_ipc = time.ipc, prop_partner = prop.partner)]
```

#### 1.5.1.2 Plot the raw data
```{r, fig.width=11, fig.height=10}
RregressPkg::plot_matrix_scatter(
  df = sperm1_dt[, !c("subject")],
  rot_y_tic_label = T,
  plot_dim = 10
)
```

<div class="takeaway">Take Away: There appears to some decrease in sperm count (*count*) as proportion of time spent together (*prop_partner*) increases </div><br>

#### 1.5.1.3 Initial OLS model
```{r}
sperm1_ols_lst <- RregressPkg::ols_calc(
  df = sperm1_dt,
  formula_obj = count ~ time_ipc + prop_partner
)
RplotterPkg::create_table(
  x = sperm1_ols_lst$coef_df,
  caption = "OLS Model Coefficients"
)
```

```{r}
RplotterPkg::create_table(
  x = sperm1_ols_lst$resid_df,
  caption = "OLS Model Residuals"
)
```

```{r}
RplotterPkg::create_table(
  x = sperm1_ols_lst$anova_df,
  caption = "OLS Model ANOVA"
)
```


#### 1.5.1.4 Check model assumptions
```{r, fig.width=11, fig.height=11}
RregressPkg::plot_residuals_check(
  df = sperm1_dt,
  formula_obj = count ~ time_ipc + prop_partner,
  id_col = "subject",
  residual_label_threshold = 120,
  leverage_label_threshold = 0.2,
  title = "Check Model Residuals",
  subtitle = "count ~ time_ipc + prop_partner",
  pts_size = 2.5,
  pts_fill = "green",
  pts_color = "black"
)
```


